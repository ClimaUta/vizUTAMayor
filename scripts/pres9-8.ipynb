{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Presentación de modelos predictivos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requerimientos\n",
    "1. Prediccion de variables climáticas con error cercano al 0%\n",
    "2. En un lapso de tiempo de al menos 24 horas\n",
    "3. Presentación de a lo menos cuatro modelos\n",
    "\n",
    "**Opcionales:**\n",
    "\n",
    "1. Generación de pronósticos a una semana\n",
    "2. Determinación de condiciones como *nublado* o *soleado*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Consideraciones\n",
    "\n",
    "### R o Python\n",
    "Si bien se posee mas experiencia de uso de R se decide ocupar Python puro para la creación de los modelos debido a la mayor disponibilidad de soporte y capacidad de paralelización de sus procesos (R sin paquetes externos no puede más de una núcleo por procesador)\n",
    "\n",
    "### Sobre set de datos\n",
    "De ahora en adelante se usara el término \"datos locales\" para hacer referencia a los datos creados mediante registros de los sensores UTA Mayor y datos DGAC a aquellos descargados desde la página de la Dirección de Aeronáutica Civil, del mismo modo, se ocupan las siglas **Ts, HR y QFE** para hacer referencia a las variables **Temperatura, Humedad relativa y Presión atmosférica** respectivamente, por **date** se hará referencia al **momento de captura** del registro\n",
    "\n",
    "### *Multivariable* y *multipaso*\n",
    "+ Un modelo multivariable es aquel que es dado por la fórmula: \n",
    "    > Var1 + Var2 = Var3 + Var4\n",
    "+ Es decir, múltiples variables de entradas son usadas para definir varias variables de salida. Estos modelos son conocidos como **MIMO** (*multiple input, multiple output*)\n",
    "+ Un modelo multipaso es aquel dado por la fórmula: \n",
    "    > Var1 = Var1(n-1) + Var1(n-2) + ... + Var1(0)\n",
    "+ Es decir, múltiples estados pasados de una variable son usados para definir el estado actual o futuro de la misma variable. Estos model son denominados **Multistep** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexto\n",
    "La confección de pronósticos climáticos es una disciplina antigua, pero que no se ejercía de forma metódica y precisa hasta la segunda mitad del siglo pasado, producto del empleo de herramientas como globos climáticos y comunicación por radio lo cual facilitaba el registro veraz y coordinado de ciertas variables atmosféricas en distintas zonas geográficas.\n",
    "Construída esta base es que Edward Lorentz definió tres posibles paradigmas para la confección de pronósticos climáticos:\n",
    "\n",
    "+ **Acercamiento dinámico**: El cual comprende la atmósfera como un gas el cual obedece las leyes de la física, y que mediante la definición de las ecuaciones que le gobiernan, se podrían determinar sus estados futuros y sus cambios conforme a alteraciones en sus variables **de entrada**. La desventaja de este paradigma es su lentitud y alto costo, pues requiere la acción coordinada de varias estaciones, en tiempo real, y poder computacional\n",
    "+ **Acercamiento empírico**: Asume que las condiciones futuras del clima futuro serán similares a las presentadas en el pasado\n",
    "    - Por ejemplo: Que el promedio de temperaturas de febrero del próximo año, será igual al febrero de este año\n",
    "    Mediante este paradigma se ampara el uso de ML para la creación de pronósticos, pues en base a eventos pasados, se puede generalizar con precisión el comportamiento de variables climáticas en el futuro. La desventaja de este enfoque es su incapacidad de predecir fenómenos no registrados o de rara ocurrencia\n",
    "+ **Acercamiento dinámico-empírico**: Fusión de los paradigmas anteriores, es el acercamiento *de facto* para la creación de pronósticos, hasta hace unas décadas era representado por el algoritmo MS5, ahora por el WFR\n",
    "\n",
    "### Importado de librerías y cargando funciones de utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uso universal\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "import sqlalchemy\n",
    "import pymysql\n",
    "import joblib\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1er modelo\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# 2do y cuarto modelo\n",
    "import tensorflow as tf\n",
    "# 3er modelo\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# import joblib\n",
    "def createTimeFeatures (dfToExpand):\n",
    "    dfToExpand['minute'] = pandas.to_datetime(dfToExpand['utc']).dt.minute\n",
    "    dfToExpand['hour'] = pandas.to_datetime(dfToExpand['utc']).dt.hour\n",
    "    dfToExpand['day'] = pandas.to_datetime(dfToExpand['utc']).dt.day\n",
    "    dfToExpand['month'] = pandas.to_datetime(dfToExpand['utc']).dt.month\n",
    "    dfToExpand['year'] = pandas.to_datetime(dfToExpand['utc']).dt.year\n",
    "    return dfToExpand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    credentials = np.genfromtxt(\"pass\",dtype='str')\n",
    "    engine = sqlalchemy.create_engine(\"mysql+pymysql://\"+credentials[0]+\":\"+credentials[1]+\"@\"+credentials[2]+\"/\"+credentials[3] )\n",
    "    mydb = engine.connect()\n",
    "    # query = \"SELECT * FROM WEATHER_MEASUREMENT WHERE serverDate >= '2021-06-26 00:00:00' AND serverDate <= '2021-08-05';\"\n",
    "    query = \"SELECT * FROM WEATHER_MEASUREMENT ORDER BY ID DESC LIMIT 34560;\"\n",
    "    arimadf = pandas.read_sql(query,mydb)\n",
    "except:\n",
    "    mydb.close() \n",
    "    print(\"error conexion a db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Iteración uno: Modelo RF preliminar**\n",
    "Con el fin de obtener de forma inmediata una línea base de efectividad a mejorar mediante la creación de nuevos modelos a la vez que un acercamiento al uso de Python para el ML, es que se inicia este proceso construyendo un bosque aleatorio **(RF)** simple que consuma los datos locales de forma cruda, este algoritmo es de especial utilidad para esta tarea puesto a que no requiere la afinación de hiperparámetros (como si los requeriría una red neuronal **-DNN-**)\n",
    "\n",
    "## Preparación de datos\n",
    "Esta iteración se destaca por el escaso preprocesamiento de datos al alimentar el modelo\n",
    "\n",
    "**Selección de datos**: Datos completamente locales (~100.000 aprox.)\n",
    "\n",
    "**Limpieza de datos**: No aplica, por el contrario no existen valores nulos en los datos locales pues son generados mediante un proceso metótico y automatizado (sensores) por lo tanto de esta iteración en adelante se omite este paso\n",
    "\n",
    "## Modelado\n",
    "+ Fórmula: Ts ~ HR + QFE + date\n",
    "+ Algoritmo seleccionado: RF\n",
    "\n",
    "## Evaluación\n",
    "El modelo no se pudo concretar\n",
    "+ El consumo de recursos computacionales es excesivo\n",
    "+ La predicción de una variable climática cada 5 segundos puede resultar innecesaria considerando que se ha de generar pronósticos a una semana en el futuro\n",
    "    - Esto resultaría en 168\\*60\\*12 predicciones, es decir ~121.000 registros por modelo\n",
    "+ Los *predictores* (HR + QFE + date) están mal definidos, pues para determinar el valor de una variable climática en el futuro solo se cuenta con un *momento* (e.g: '2021-08-08 12:00:00) y no con valores de HR o QFE\n",
    "\n",
    "Este problema se puede solucionar eliminando del set de datos de entrenamiento las variables HR y QFE, pero genera otros inconvenientes.\n",
    "Solo se cuenta con datos tipo fecha, los cuales en este formato se comportan como un escalar (e.g: valores de 0 a 1000 con pasos de uno en uno) lo cual puede no ser útil para la detección de patrones por parte de los modelos. Ante esta situación se plantean tres opciones:\n",
    "    \n",
    "1. Si se asume que para alimentar al modelo solo se cuenta con **momentos (o fechas)** pasadas para pronósticos futuros, se podría aplicar análisis de **series de tiempo** en los datos, y por tanto todas las herramientas ya desarrolladas para este tipo de fenómenos\n",
    "    > Fórmula: Ts(n) ~ Ts(n-1) + Ts(n-2) + ...\n",
    "2. Por otra parte, la descomposición de fechas en **características de tiempo**, es decir, minutos, horas, días y meses, es intuitivamente útil, pues si el modelo logra relacionar por ejemplo el promedio de temperaturas de julio con un valor más bajo que el promedio de junio, se obtendría un pronóstico básico, pero funcional\n",
    "    > Fórmula: Ts(n) ~ H + D + M \n",
    "3. Por último, apegándose mas a la definición de *acercamiento empírico*, se asume que las condiciones climáticas futuras son definidas de forma importante por las condiciones pasadas, por lo tanto se puede construir un **mapeo** de una serie de condiciones pasadas (incluyendo HR y QFE) a un momento futuro de éstas mismas variables\n",
    "    > Fórmula: Ts(n) ~ Ts(n-1) + HR(n-1) + QFE(n-1)\n",
    "\n",
    "> *Nota*: Todas estas fórmulas pueden aplicarse en su forma multivariable (**MIMO**) en cuanto el algoritmo a ocupar lo permita, por lo tanto una fórmula del tipo (Ts+HR+QFE)(n) ~ H + D + M es perfectamente válida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Iteración dos: Modelo DNN**\n",
    "Tomando en cuenta la evaluación del modelo anterior es que en esta iteración se comienza a hacer preprocesamiento de datos, proceso el cual también conlleva a tomar decisiones en un contexto de **costo-beneficio**, pues la construcción y formateo de datos estará alterando la ***realidad*** registrada por los sensores en pos de alimentar a los modelos ML con información la cual sea consistente y eficiente de procesar en vez de *real*. La estrategia de preprocesamiento en esta iteración corresponde a una mezcla entre las opciones **2 y 3** de la sección anterior\n",
    "\n",
    "## Preparación de datos\n",
    "**Selección de datos**: Para disminuir el uso de recursos computacionales se decide hacer **agrupamiento de los registros** por minuto, disminuyendo 12 veces el tamaño del dataset original. \n",
    "\n",
    "**Construcción**: El agrupamiento de datos por medio de minutos reveló **gaps** entre los registros, los cuales deben ser rellenados si se desea aplicar el método 3 pues, por ejemplo, una temperatura de las 8am podría ser definida por la Ts de las 1am, último Ts registrado antes de un periodo de baja del servicio. En python esta operación se denomina **interpolado**\n",
    "\n",
    "**Formateo**: Para las redes neuronales, este es un paso obligatorio, las transformaciones que han de aplicarse para alimentar una DNN de *tensorflow* incluye:\n",
    "\n",
    "+ Descomposición de tiempo: La DNN es incapaz de procesar datos tipo *date*    \n",
    "+ Interpolado: Es incapaz de procesar datos nulos\n",
    "+ Normalización: Las DNN son sensibles a los valores fuera de un rango (-1,1) pues valores muy altos pueden falsamente anunciarse como cambios de alta importancia y propagarse entre las neuronas a pesar de ser simplemente el promedio de una variable (e.g: Ts vs QFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Modelado\n",
    "+ Características del modelo: Mutlivariable\n",
    "+ Fórmula: Ts(n) ~ Ts(n-1) + min + H + D + M\n",
    "+ Algoritmo seleccionado: DNN, 4 capas densas, Entradas \\[7,] -> Salida\\[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preparación de datos\n",
    "## Seleccion\n",
    "df = pandas.read_csv(\"./WEATHER_MEASUREMENT.csv\")\n",
    "df[\"utc\"] = pandas.to_datetime(df[\"dateUTC\"],format='%Y-%m-%d %H:%M:%S')\n",
    "df = df.groupby(pandas.Grouper(key=\"utc\",freq='min')).mean()    \n",
    "toKeep = ['AMBIENT_TEMPERATURE','AIR_PRESSURE','HUMIDITY']\n",
    "df = df[toKeep]\n",
    "df = df.reset_index()\n",
    "df.columns = ['utc','Ts_Valor','QFE_Valor','HR_Valor']\n",
    "df = df[['Ts_Valor','HR_Valor','QFE_Valor','utc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Construcción\n",
    "df = df.interpolate(method = 'linear')\n",
    "## Formateo\n",
    "df = createTimeFeatures(df)\n",
    "dates_df = df.pop('utc')\n",
    "df.pop('year')\n",
    "## Normalizado\n",
    "train_mean = df.mean()\n",
    "train_std = df.std()\n",
    "df = (df - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modelado\n",
    "## Creación de *labels* para utilizar como resultados de fórmula\n",
    "topred = df[['Ts_Valor','HR_Valor','QFE_Valor']]\n",
    "topred = topred[1:]\n",
    "topred = topred.reset_index(drop=True)\n",
    "# topred = (topred - train_mean[['Ts_Valor','HR_Valor','QFE_Valor']]) / train_std[['Ts_Valor','HR_Valor','QFE_Valor']]\n",
    "df = df[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Creación datasets de entrenamiento y testeo\n",
    "lendf = len(df)\n",
    "lendf = round(lendf*0.9)\n",
    "train_df = df[0:lendf]\n",
    "train_labels = topred[0:lendf]\n",
    "test_df = df[lendf:len(df)]\n",
    "test_labels = topred[lendf:len(df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49012, 3)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topred.tail()\n",
    "topred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49012, 7)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modelado\n",
    "features = test_df.shape[1]\n",
    "train_df = np.array(train_df)\n",
    "test_df = np.array(test_df)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "nnHM = tf.keras.Sequential()\n",
    "nnHM.add(tf.keras.layers.Dense(168,input_shape=(features,)))\n",
    "nnHM.add(tf.keras.layers.Dense(72,input_shape=(features,)))\n",
    "nnHM.add(tf.keras.layers.Dense(24,activation='relu'))\n",
    "nnHM.add(tf.keras.layers.Dense(3))\n",
    "# nnHM.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1172/1172 [==============================] - 14s 11ms/step - loss: 0.1573 - mean_squared_error: 0.0894 - val_loss: 0.4396 - val_mean_squared_error: 0.5600\n",
      "Epoch 2/3\n",
      "1172/1172 [==============================] - 13s 12ms/step - loss: 0.1031 - mean_squared_error: 0.0307 - val_loss: 0.2169 - val_mean_squared_error: 0.0921\n",
      "Epoch 3/3\n",
      "1172/1172 [==============================] - 13s 11ms/step - loss: 0.0806 - mean_squared_error: 0.0235 - val_loss: 0.2779 - val_mean_squared_error: 0.1230\n"
     ]
    }
   ],
   "source": [
    "## Compilado de modelo\n",
    "nnHM.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    #learning_rate = 0.001\n",
    "    loss='mae', # 'mean_absolute_error',\n",
    "    metrics=[tf.keras.metrics.MeanSquaredError()] \n",
    ")\n",
    "history = nnHM.fit(\n",
    "    train_df, train_labels,\n",
    "    epochs=3,\n",
    "    verbose=1,\n",
    "    shuffle=False,\n",
    "    validation_split=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = nnHM.predict(test_df)\n",
    "stackPreds = pandas.DataFrame(x)\n",
    "stackPreds.columns = ['Ts_Valor','HR_Valor','QFE_Valor']\n",
    "test_labels = pandas.DataFrame(test_labels)\n",
    "test_labels.columns = ['Ts_Valor','HR_Valor','QFE_Valor']\n",
    "test_labels = test_labels.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### NO CORRER\n",
    "# De normalizacion\n",
    "stackPreds = stackPreds * train_std + train_mean\n",
    "test_labels = test_labels * train_std + train_mean\n",
    "#stackPreds.plot(subplots=True)\n",
    "#test_labels.plot(subplots=True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluación\n",
    "A primera vista pareciera que el modelo tiene una alta capacidad predictiva debido a los errores promedio cercanos a cero considerando la varianza original de los datos. Lo cual se confirma al apreciar la cercanía entre las líneas dibujadas por las predicciones y el dataset de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "plt.plot(stackPreds['Ts_Valor'],label=\"Predicciones DNN\")\n",
    "plt.plot(test_labels['Ts_Valor'],label=\"Test Labels\")\n",
    "plt.title(\"Predicciones de temperatura - Modelo DNN - Fórmula: (Ts+HR+QFE)(n) ~ (Ts+HR+QFE)(n-1) + TimeFeatures\")\n",
    "plt.ylabel(\"Temperatura (°C)\")\n",
    "plt.xlabel(\"Cantidad de minutos en el futuro\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HR_Valor     0.034780\n",
       "QFE_Valor    2.160599\n",
       "Ts_Valor     0.074774\n",
       "day               NaN\n",
       "hour              NaN\n",
       "minute            NaN\n",
       "month             NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = stackPreds - test_labels\n",
    "a.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Implementación\n",
    "Obedeciendo la fórmula de este modelo: **Ts(n) ~ Ts(n-1) + min + H + D + M**\n",
    "\n",
    "Es que las predicciones que este genera deben ser retroalimentadas como *input* para la generación de una siguiente predicción o **paso**, en este momento es donde el modelo falla de forma evidente como se puede ver en la siguiente gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ts_Valor</th>\n",
       "      <th>HR_Valor</th>\n",
       "      <th>QFE_Valor</th>\n",
       "      <th>minute</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.564649</td>\n",
       "      <td>1.005445</td>\n",
       "      <td>1.379337</td>\n",
       "      <td>-1.703241</td>\n",
       "      <td>-1.662508</td>\n",
       "      <td>-1.770372</td>\n",
       "      <td>3.187065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ts_Valor  HR_Valor  QFE_Valor    minute      hour       day     month\n",
       "0 -0.564649  1.005445   1.379337 -1.703241 -1.662508 -1.770372  3.187065"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = [18.955,55.959,1012.699,0,0,1,8]\n",
    "r = pandas.DataFrame(r).transpose()\n",
    "r.columns = ['Ts_Valor','HR_Valor','QFE_Valor','minute','hour','day','month']\n",
    "r = (r-train_mean)/train_std\n",
    "r = r[['Ts_Valor','HR_Valor','QFE_Valor','minute','hour','day','month']]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "now = pandas.to_datetime('2021-07-29 18:00:00')\n",
    "features = test_df.shape[1]\n",
    "x = nnHM.predict(r)\n",
    "stackPreds = pandas.DataFrame()\n",
    "for i in range(20):\n",
    "    delta = now + datetime.timedelta(0,i*60)\n",
    "    #temp = np.array([x,y,z,delta.hour,delta.day,delta.month],dtype=\"float32\")\n",
    "    temp = np.array([x[0,0],x[0,1],x[0,2],delta.minute,delta.hour,delta.day,delta.month],dtype=\"float32\")\n",
    "    stackPreds = stackPreds.append(pandas.DataFrame(temp).transpose())\n",
    "    # Formateando registro para alimentar el modelo\n",
    "    temp_RE = np.reshape(temp,(-1,features))\n",
    "    x = nnHM.predict(temp_RE)\n",
    "\n",
    "stackPreds.columns = ['Ts_Valor','HR_Valor','QFE_Valor','minute','hour','day','month']\n",
    "stackPreds = stackPreds * train_std + train_mean\n",
    "stackPreds = stackPreds.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_labels = test_labels.reset_index(drop=True)\n",
    "plt.plot(stackPreds['Ts_Valor'],label=\"Predicciones DNN\")\n",
    "plt.plot(test_labels[['Ts_Valor']],label=\"Test Labels\")\n",
    "plt.title(\"Predicciones de temperatura - Modelo DNN - Fórmula: (Ts+HR+QFE)(n) ~ (Ts+HR+QFE)(n-1) + TimeFeatures\")\n",
    "plt.ylabel(\"Temperatura (°C)\")\n",
    "plt.xlabel(\"Cantidad de minutos en el futuro\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La falla de este modelo recae en su fórmula **Ts(n) ~ Ts(n-1) + min + H + D + M** , la cual indica que todas las predicciones son mayormente dependientes de sus valores inmediatamente anteriores (Ts(n) ~ Ts(n-1)) y además al hecho de haber aprendido en mayor parte el **comportamiento lineal** de los datos, el cual fue inducido al momento de hacer interpolado con tal de obtener un dataset consistente.\n",
    "\n",
    "Ante la incapacidad de los modelos de retroalimentarse y generar predicciones fiables no tan dependientes de los registros inmediatamente anteriores captados se idea una serie de formas posibles de apalear los efectos de este fenomeno y se comentan sus posible desventajas:\n",
    "+ **No proveer de la varible minuto a los registros**: Considerando que las predicciones:\n",
    "    1. O son incapaces de entender los minutos como un simple componente de hora, es decir que los minutos de la hora 16 tienen distinto comportamiento que los minutos de la hora 3 am\n",
    "    2. O la variable minuto simplemente provee rigidez al modelo, debido a su comportamiento lineal, lo cual lo hace incapaz de reconocer la mayor importancia de mapear en 1er lugar e.g: hora -> temperatura\n",
    "+ Agrandar los gaps entre los registros: A hora o días, pues los comportamientos lineales de los tiempos de downtime son *extensos* considerando la granularidad de los registros, lo cual afecta negativamente la deteccion de periodicidad en los datos\n",
    "    > Una iteración 2.5 demostró que esta solución no es viable\n",
    "+ **Mejorar interpolacion**: Preferentemente mediante una funcion sinusoidal que imite los ciclos naturales diarios de las variables climáticas\n",
    "    1. Imposible aplicar para humedad relativa con datos locales, su comportaminento es muy errático\n",
    "    2. Disponibilidad: se requiere al menos un par de dias de registros sin downtime o integración de datos externos\n",
    "    3. Alta complejidad: pues requeriria ya un modelo de prediccion funcional tan solo para hacer preprocesamiento\n",
    "+ **Integración de datos**: Dgac y locales, sobreescribiendo los datos locales en los datos Dgac, de esta forma los modelos tienen mayor espacio para aprender los ciclos de las variables\n",
    "    1. Se perderia una enorme cantidad de datos (720 veces menos datos)\n",
    "+ Mapeos mas extensos: Conocido también como **sistema de ventanas**, consiste en relacionar una mayor cantidad de datos por cada *label*\n",
    "    1. e.g: matriz6horasDeDatos[][] -> prediccion1hora[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomando en cuenta los aprendizajes obtenidos mendiante la visualización de datos es que se opta por aplicar soluciones incluyendo los puntos 1, 4 y 5, y retomando las opciones 1 y 2 mencionadas en la iteración uno, las cuales no empleaban variables que requieren retroalimentación, pues dependen únicamente de la fecha de los registros y comportamientos cíclicos *univariables*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Iteración tres: Modelo ARIMA**\n",
    "Un modelo autorregresivo de promedio móvil integrado (ARIMA) es un modelo estadístico que utiliza variaciones y regresiones de datos estadísticos con el fin de encontrar patrones para una predicción hacia el futuro [\\[1\\]](https://es.wikipedia.org/wiki/Modelo_autorregresivo_integrado_de_media_m%C3%B3vil) .\n",
    "\n",
    "Este tipo de modelos son *univariables* pero requieren que el usuario indique, como mínimo, la periodicidad percibida de la serie de tiempo a estudiar, como se conoce que la mayoría de variables climáticas dibujan ciclos de 24 horas de acuerdo a las horas del día, se puede construir un modelo ARIMA por cada variable [\\[2\\]](https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/).\n",
    "\n",
    "## Preparación de datos\n",
    "**Selección de datos**: Últimos dos días de registros locales (~35.000 aprox.) agrupados por hora.\n",
    "> Una iteración 3.5 demostró que el uso de dataset de dataset agrupados por minuto genera una excesiva carga computacional y tamaño de modelo (~ 2 gb) \n",
    "\n",
    "**Construcción**: Interpolado lineal \n",
    "\n",
    "**Formateo**: Tarea extensa debido al tipo de index el cual consume el modelo, que debe ser de tipo *date* con frecuencia horaria explicitada, el cual además para subir a DB, debe pasar por un proceso inverso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Modelado\n",
    "+ Fórmula: Ts(n) = Ts(n-1) + Ts(n-2) + ... + Ts(0)\n",
    "+ Algoritmo: ARIMA del paquete 'statsmodels' (en rigor es un SARIMAX), periodicidad cada 24 registros y grado de integración 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-327-44c49a53ab8d>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"utc\"] = pandas.to_datetime(df[\"serverDate\"],format='%Y-%m-%d %H:%M:%S')\n"
     ]
    }
   ],
   "source": [
    "df = df.iloc[::-1] # dando vuelta el dataframe\n",
    "df = arimadf.iloc[::-1] # dando vuelta el dataframe\n",
    "df[\"utc\"] = pandas.to_datetime(df[\"serverDate\"],format='%Y-%m-%d %H:%M:%S')\n",
    "df = df[['AMBIENT_TEMPERATURE','AIR_PRESSURE','HUMIDITY','utc']]\n",
    "df = df.reset_index(drop=True)\n",
    "df2 = df.groupby(pandas.Grouper(key=\"utc\",freq='H')).mean()\n",
    "df2 = df2.interpolate(method='linear')\n",
    "series = df2\n",
    "series.index = series.index.to_period('H')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Una de las mejores caracteristicas de los modelos ARIMA (o al menos su implementacion en pyhon) es que puede hacer bulk de predicciones con tan solo un valor futuro fijo de la serie de tiempo (o sea una fecha futura arbitraria), sin embargo al mismo tiempo dependera complemente de los ultimos steps que el mismo modelo va creando, los cuales van disminuyendo a través del tiempo, convergiendo las prediccioes en el promedio de las variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "future = 72\n",
    "\n",
    "stackPreds = pandas.DataFrame()\n",
    "model = ARIMA(series['AMBIENT_TEMPERATURE'], order=(24,1,0))\n",
    "model_fit = model.fit()\n",
    "stackPreds['AMBIENT_TEMPERATURE'] = model_fit.forecast(future)\n",
    "model = ARIMA(series['HUMIDITY'], order=(24,1,0))\n",
    "model_fit = model.fit()\n",
    "stackPreds['HUMIDITY'] = model_fit.forecast(future)\n",
    "model = ARIMA(series['AIR_PRESSURE'], order=(24,1,0))\n",
    "model_fit = model.fit()\n",
    "stackPreds['AIR_PRESSURE'] = model_fit.forecast(future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "series.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackPreds.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, el modelo genera gráficas que en mayor parte se asemejan a los comportamientos de las variables que le fueron proveídas, el principal objetivo de esta iteración fue alcanzado pues se construyó un modelo el cual puede consumir sus propias predicciones como input y dar *pasos en el futuro* de forma estable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Iteración cuatro: Modelo DNN - solo tiempo**\n",
    "Continuando con la premisa del modelo ARIMA (es decir, el valor actual de las variables dependen únicamente de sus momentos pasados) es que mediante un modelo DNN, adaptamos esta premisa a los algoritmos de aprendizaje automáticos modernos. De esta forma, de forma computacional, la variable a predecir ya no consume un bulk de sus estados pasados, sino que se construye un mapeo \n",
    "> Momento (pasado o futuro) -> Variable\n",
    "\n",
    "El cual generalize mejor los mapeos \"momento -> variable\" pasados. De esta forma los nuevos *inputs* del modelo se convierten en **características de tiempo** como hora, día y mes, los cuales siempre existirán y no requieren que el modelo consuma sus propias predicciones\n",
    "A diferencia de ARIMA, un DNN construído de forma manual en *tensorflow* puede ser de *output* multivariable, y además se puede controlar con precisión los comportamientos internos de la red neuronal como la cantidad de capas y forma de activación.\n",
    "\n",
    "## Preparación de datos\n",
    "**Selección de datos**: Proveer de datos consistentes y extensos es de vital importancia en el aprendizaje automático por lo que se emplean todos los registros locales disponibles agrupados por hora y además se hace selección de datos externos para complementar\n",
    "\n",
    "**Construcción**: Sabiendo que los gaps de nuestros datos locales van a ser suplidos por externos, este paso no aplica de aquí en adelante\n",
    "\n",
    "**Integración**: Se integran datos externos proveídos por DGAC de 2019 y 2020 para rellenar nuestros registros faltantes, este paso se aplica para todas las iteraciones de aquí en adelante\n",
    "\n",
    "**Formateo**: Incluye descomposición de tiempo y normalización "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modelado\n",
    "+ Fórmula: Ts(n) ~ H + D + M , en su versión multivariable (Ts+HR+QFE)(n) ~ H + D + M\n",
    "+ Algoritmo: Stack de 5 capas de redes neuronales densas (*fully connected neurons* sin métodos internos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"./dataPreprocessed.csv\")\n",
    "df = createTimeFeatures(df)\n",
    "df = df[['Ts_Valor','HR_Valor','QFE_Valor','hour','day','month']]\n",
    "\n",
    "lendf = len(df)\n",
    "lendf = round(lendf*0.998)\n",
    "train_df = df[0:lendf]\n",
    "test_df = df[lendf:len(df)]\n",
    "\n",
    "varToPred = 'Ts_Valor'\n",
    "varToPred = ['Ts_Valor','HR_Valor','QFE_Valor']\n",
    "train_labels = df[varToPred][0:len(train_df)]\n",
    "test_labels = df[varToPred][lendf:]\n",
    "\n",
    "# salvando valores de test para autoregresiones\n",
    "rtTest = test_df.copy()\n",
    "rtTest_labels = test_labels.copy()\n",
    "\n",
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std\n",
    "train_labels = (train_labels - train_mean[varToPred]) / train_std[varToPred]\n",
    "test_labels = (test_labels - train_mean[varToPred]) / train_std[varToPred]\n",
    "\n",
    "train_df = train_df[['hour','day','month']]\n",
    "test_df = test_df[['hour','day','month']]\n",
    "features = train_df.ndim + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = np.array(train_df)\n",
    "#test_df = np.array(test_df)\n",
    "train_labels = np.array(train_labels)\n",
    "#test_labels = np.array(test_labels)\n",
    "\n",
    "nnHM = tf.keras.Sequential()\n",
    "nnHM.add(tf.keras.layers.Dense(672,input_shape=(3,)))\n",
    "nnHM.add(tf.keras.layers.Dense(168,activation='relu'))\n",
    "nnHM.add(tf.keras.layers.Dense(72,activation='relu'))\n",
    "nnHM.add(tf.keras.layers.Dense(24,activation='relu'))\n",
    "nnHM.add(tf.keras.layers.Dense(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "832/832 [==============================] - 14s 16ms/step - loss: 0.5516 - mean_squared_error: 0.5189 - val_loss: 0.8333 - val_mean_squared_error: 1.0421\n",
      "Epoch 2/2\n",
      "832/832 [==============================] - 14s 17ms/step - loss: 0.5443 - mean_squared_error: 0.5137 - val_loss: 0.8117 - val_mean_squared_error: 1.0124\n"
     ]
    }
   ],
   "source": [
    "nnHM.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    #learning_rate = 0.001\n",
    "    loss='mae', # 'mean_absolute_error',\n",
    "    metrics=[tf.keras.metrics.MeanSquaredError()] # you were running metrics with 'accuracy' lol\n",
    ")\n",
    "history = nnHM.fit(\n",
    "    train_df, train_labels,\n",
    "    epochs=2,\n",
    "    verbose=1,\n",
    "    shuffle=False,\n",
    "    validation_split=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackPreds.plot(subplots=True)\n",
    "test_labels.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#x = nnHM.predict(test_df)\n",
    "nnHM = tf.keras.models.load_model('../deepNN-multiV2')\n",
    "x = nnHM.predict(test_df)\n",
    "\n",
    "stackPreds = pandas.DataFrame(x)\n",
    "stackPreds.columns = ['Ts_Valor','HR_Valor','QFE_Valor']\n",
    "test_labels = pandas.DataFrame(test_labels)\n",
    "test_labels.columns = ['Ts_Valor','HR_Valor','QFE_Valor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stackPreds = stackPreds * train_std + train_mean\n",
    "test_labels = test_labels * train_std + train_mean\n",
    "stackPreds = stackPreds.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(stackPreds['Ts_Valor'],label=\"Predicciones\")\n",
    "plt.plot(test_labels['Ts_Valor'],label=\"Test Labels\")\n",
    "plt.title(\"Predicciones de temperatura - Modelo DNN - Fórmula: Ts ~ h + d + m\")\n",
    "plt.ylabel(\"Temperatura (°C)\")\n",
    "plt.xlabel(\"Horas en el futuro desde el 31-07 03:00\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(stackPreds['HR_Valor'],label=\"Predicciones\")\n",
    "plt.plot(test_labels['HR_Valor'],label=\"Predicciones\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"Predicciones de humedad relativa - Modelo DNN - Fórmula: HR ~ h + d + m\")\n",
    "plt.ylabel(\"Humedad relativa (%)\")\n",
    "plt.xlabel(\"Horas en el futuro desde el 31-07 03:00\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HR_Valor     42.595942\n",
       "QFE_Valor     3.570640\n",
       "Ts_Valor      0.897967\n",
       "day                NaN\n",
       "hour               NaN\n",
       "month              NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ((stackPreds - test_labels) * (stackPreds - test_labels)).mean()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, el modelo genera gráficas que en mayor parte se asemejan a los comportamientos de las variables en el set de datos de testeo, sin embargo cabe mencionar ciertas observaciones a mejorar en futuras iteraciones:\n",
    "+ Las predicciones tienen un comportamiento de **señal** más que alguno de fenómeno natural. Esto se debe a que:\n",
    "    - El modelo consume variables estáticas, es decir a través de los años los componentes **H, D y M** siempre tienen el mismo comportamiento (ir de 1 a 24, 1 a 30 y 1 a 12 respectivamente), por lo que en resumen, el modelo no hace mas que **mapear los mejores promedios a distintos momentos del año**\n",
    "    - Este fenómeno era esperable dada la fórmula que define el modelo, el cual consume valores constantes\n",
    "+ Los valores de error promedio calculado van en conjunto con lo expuesto, pues en visualizaciones de datos preliminares ya se observaba que las variables Ts y QFE tenían un comportamiento cíclico rígido y, por el contrario, HR era la variable con más ruido\n",
    "\n",
    "De esta forma, esta iteración confirma la **importancia** que tiene el alimentar al modelo con registros de variables pasadas, esta vez, abasteciendo con suficientes datos históricos con diferencias significantes para privilegiar la detección de **ciclos (o estacionalidad)** y en segundo lugar el efecto de registros inmediatemente anteriores sobre la predicción final.\n",
    "\n",
    "> Una solución alternativa, pero que conceptualmente no es diferente a lo desarrollado en esta iteración, es el forzar el comportamiento de señal en las variables, mediante la aplicación de transformaciones tipo **H = sin(H)** y **D + M = sin(D + M)** con tal de explicitar los ciclos diarios y anuales de cada variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Iteración cinco: Modelo RF**\n",
    "Tomando en cuenta la evaluación de la iteración pasada, es que esta vez el modelo a generar debe captar ciclos de variables a la vez que ser \n",
    "sensible a los valores inmediatamente anteriores de otras condiciones climáticas.\n",
    "Por lo que para esta iteración se retoma la fórmula Ts(n) ~ Ts(n-1) + min + H + D + M pero eliminando el componente minutos e incrementando la cantidad de información de entrenamiento mediante la integración de datos de DGAC\n",
    "\n",
    "La afinación de una regresión y el modelo detrás de este es un proceso costoso computacionalmente a la vez que inestable, problemas propios de las redes neuronales como *exploding/vanishing gradient* fueron presensiados en iteraciones pasadas pero no mencionadas para mantener el *notebook* fluido, al mismo tiempo, las diferentes formas de normalizar e interpolar datos añaden mayor complejidad y variables que deben ser meticulosamente traceadas y guardadas al momento de creación de un modelo NN\n",
    "Ante estas dificultades es que se vuelve a aplicar un modelo RF, el cual no presenta los problemas descritos pues simplemente divide y promedia la serie de árboles de decisión que construye para generar una regresión\n",
    "\n",
    "## Preparación de datos\n",
    "**Selección de datos**: Datos locales y DGAC (2 años) agrupados por hora\n",
    "\n",
    "**Integración**: Se escribe nuestros datos locales sobre los registros DGAC mediante una operación *join&replace*\n",
    "\n",
    "**Formateo**: Descomposición de tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modelado\n",
    "+ Fórmula: Ts(n) ~ Ts(n-1) + HR(n-1) + QFE(n-1) + H + D + M + Y\n",
    "+ Algoritmo seleccionado: RF, su implementación en python permite *output* multivariable (Entradas \\[7,] -> Salida\\[3]) a la vez que mapeo por ventanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seleccion e integración\n",
    "df = pandas.read_csv(\"./dataPreprocessed.csv\")\n",
    "df = createTimeFeatures(df)\n",
    "df.pop('minute')\n",
    "dates_df = df.pop('utc')\n",
    "\n",
    "# Preparación de datos y labels para cumplir con fórmula\n",
    "topred = df[['Ts_Valor','HR_Valor','QFE_Valor']]\n",
    "topred = topred[1:]\n",
    "df = df[:-1]\n",
    "\n",
    "# Dividiendo dataset\n",
    "lendf = len(df)\n",
    "lendf = round(lendf*0.9)\n",
    "train_df = df[0:lendf]\n",
    "train_labels = topred[0:lendf]\n",
    "test_df = df[lendf:len(df)]\n",
    "test_labels = topred[lendf:len(df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rfabc = RandomForestRegressor()\n",
    "# rfabc.fit(train_df,train_labels)\n",
    "rfMultivar=joblib.load('../../pyRF/rf-multivarOffset.joblib')\n",
    "\n",
    "predRF = rfMultivar.predict(test_df)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pandas.DataFrame(predRF).plot(subplots=True)\n",
    "#test_labels.plot(subplots=True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ts_Valor     0.095336\n",
       "HR_Valor     0.051294\n",
       "QFE_Valor   -0.002888\n",
       "dtype: float64"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ((predRF - test_df[['Ts_Valor','HR_Valor','QFE_Valor']]))\n",
    "a.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, el modelo genera gráficas que se asemejan mucho a los comportamientos de las variables en el set de datos de testeo, sin embargo, esto es solo una línea base, la principal misión de este modelo es demostrar la capacidad de consumir sus propias predicciones conservando la estacionalidad de las variables climáticas, de esta forma se genera un nuevo plan de evaluación el cual desarrolla esta procedimiento, resultando en las siguientes predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "now = pandas.to_datetime('2021-07-29 09:00:00')\n",
    "stackPreds = pandas.DataFrame()\n",
    "x = rfMultivar.predict(train_df[len(train_df)-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0,72):\n",
    "    delta = now + datetime.timedelta(0,i*3600)\n",
    "    #temp = np.array([x,y,z,delta.hour,delta.day,delta.month],dtype=\"float32\")\n",
    "    temp = np.array([x[0,0],x[0,1],x[0,2],delta.hour,delta.day,delta.month,delta.year],dtype=\"float32\")\n",
    "    stackPreds = stackPreds.append(pandas.DataFrame(temp).transpose())\n",
    "    # Formateando registro para alimentar el modelo\n",
    "    temp_RE = np.reshape(temp,(-1,7))\n",
    "    x = rfMultivar.predict(temp_RE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stackPreds = stackPreds.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "stackPreds.columns = ['Ts_Valor','HR_Valor','QFE_Valor','h','d','m','y']\n",
    "stackPreds = stackPreds[['Ts_Valor','HR_Valor','QFE_Valor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackPreds.plot(subplots=True)\n",
    "test_labels.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ts_Valor    -1.019569\n",
       "HR_Valor     8.477222\n",
       "QFE_Valor    1.214352\n",
       "dtype: float64"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ((stackPreds - test_df[['Ts_Valor','HR_Valor','QFE_Valor']][0:72]))\n",
    "x.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar el error promedio ha aumentado considerablemente en comparación al anteriormente expuesto, sin embargo, es un pronóstico indiscutiblemente más optimista que el presentado en la **iteración 2**, ocupando la **misma fórmula**. Este proceso de retroalimentación garantiza la autonomía del modelo durante largos periodos de tiempo y por lo tanto, está listo para ser implementado como servicio con capacidad predictiva básica.\n",
    "\n",
    "Por último, se adjunta una gráfica donde se evidencia la diferencia de error promedio entre las predicciones autónomas y aquellas generadas mediante mapeo *'test_df(n) -> predicción(n+1)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_df['Ts_Valor'],label='testDF')\n",
    "plt.plot(predRF[0:,0],label='predTestDF')\n",
    "plt.plot(stackPreds['Ts_Valor'],label='predAutonoma')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Iteración seis: Modelo recurrente -LSTM-**\n",
    "\n",
    "\n",
    "## Preparación de datos\n",
    "**Selección de datos**: Ídem iteración anterior\n",
    "\n",
    "**Integración**: Ídem iteración anterior\n",
    "\n",
    "**Formateo**: Además de normalizar y descomponer la fecha de registro de forma tradicional, para cumplir con el objetivo de implementar un sistema de ventanas, se hace uso de un **generador de series de tiempo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Modelado\n",
    "+ Fórmula: **Ts(n) ~ Ts(n-1) + Ts(n-2) + ... + Ts(n-24) + H + D + M** , en su versión multivariable (Ts+HR+QFE)(n)\n",
    "+ Algoritmo seleccionado: LSTM con capas densas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"./dataPreprocessed.csv\")\n",
    "df = createTimeFeatures(df)\n",
    "dates_df = df.pop('utc')\n",
    "dates_df = df.pop('minute')\n",
    "dates_df = df.pop('year')\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizado\n",
    "train_mean = df.mean()\n",
    "train_std = df.std()\n",
    "df = (df - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creación datasets de entrenamiento y testeo\n",
    "lendf = len(df)\n",
    "lendf = round(lendf*0.9)\n",
    "train_df = df[0:lendf]\n",
    "train_labels = df[['Ts_Valor','HR_Valor','QFE_Valor']][0:lendf]\n",
    "#train_labels = df[0:lendf]\n",
    "test_df = df[lendf:len(df)]\n",
    "test_labels = df[['Ts_Valor','HR_Valor','QFE_Valor']][lendf:len(df)]\n",
    "#test_labels = df[lendf:len(df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.to_numpy()\n",
    "test_df = test_df.to_numpy()\n",
    "train_labels = train_labels.to_numpy()\n",
    "test_labels = test_labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "winSize = 24 # passing events as 24hr windows\n",
    "numFeatures = 6 # we are passing all available features, you can replace 'month' by 'cos'\n",
    "train_gen = tf.keras.preprocessing.sequence.TimeseriesGenerator(train_df,train_labels,length=winSize)\n",
    "test_gen = tf.keras.preprocessing.sequence.TimeseriesGenerator(test_df,test_labels,length=winSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the Array: \n",
      "[[ 0.87972626  0.16462007 -1.4166927  -1.66145972 -1.67374551 -1.51053581]\n",
      " [ 1.00995708 -0.38206422 -1.20653737 -1.51699757 -1.67374551 -1.51053581]\n",
      " [ 0.94484167 -0.38206422 -1.16450631 -1.37253542 -1.67374551 -1.51053581]\n",
      " [ 0.87972626 -0.38206422 -1.45872377 -1.22807327 -1.67374551 -1.51053581]\n",
      " [ 0.78205315 -0.24539315 -1.75294123 -1.08361112 -1.67374551 -1.51053581]\n",
      " [ 0.65182233 -0.10872208 -2.13122082 -0.93914898 -1.67374551 -1.51053581]\n",
      " [ 0.74949544 -0.38206422 -2.42543829 -0.79468683 -1.67374551 -1.51053581]\n",
      " [ 0.71693774 -0.38206422 -2.76168681 -0.65022468 -1.67374551 -1.51053581]\n",
      " [ 0.58670692 -0.24539315 -2.84574895 -0.50576253 -1.67374551 -1.51053581]\n",
      " [ 0.19601448  0.84797544 -2.55153148 -0.36130038 -1.67374551 -1.51053581]\n",
      " [ 0.22857218  0.71130437 -2.13122082 -0.21683823 -1.67374551 -1.51053581]\n",
      " [ 0.4239184   0.30129115 -1.83700336 -0.07237608 -1.67374551 -1.51053581]\n",
      " [ 0.87972626 -0.38206422 -1.6688791   0.07208606 -1.67374551 -1.51053581]\n",
      " [ 1.04251478 -0.5187353  -1.71091016  0.21654821 -1.67374551 -1.51053581]\n",
      " [ 1.1727456  -0.24539315 -1.83700336  0.36101036 -1.67374551 -1.51053581]\n",
      " [ 1.30297641 -0.5187353  -1.96309656  0.50547251 -1.67374551 -1.51053581]\n",
      " [ 1.43320723 -0.65540637 -2.25731402  0.64993466 -1.67374551 -1.51053581]\n",
      " [ 1.40064953 -0.5187353  -2.38340722  0.79439681 -1.67374551 -1.51053581]\n",
      " [ 1.66111116 -0.79207745 -2.55153148  0.93885896 -1.67374551 -1.51053581]\n",
      " [ 1.59599575 -1.20209067 -2.34137615  1.0833211  -1.67374551 -1.51053581]\n",
      " [ 1.53088034 -1.06541959 -2.50950042  1.22778325 -1.67374551 -1.51053581]\n",
      " [ 1.36809182 -0.5187353  -2.59356255  1.3722454  -1.67374551 -1.51053581]\n",
      " [ 1.1727456   0.027949   -2.55153148  1.51670755 -1.67374551 -1.51053581]\n",
      " [ 1.1727456   0.027949   -2.17325189  1.6611697  -1.67374551 -1.51053581]]\n",
      "Predict this y: \n",
      " [ 1.07507249  0.027949   -1.92106549]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "X,y = train_gen[0]\n",
    "print(f'Given the Array: \\n{X[0]}')\n",
    "print(f'Predict this y: \\n {y[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-357-52ae9ed2bc1e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-357-52ae9ed2bc1e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Given the Array:\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Given the Array: \n",
    "[[  21.6   68.  1005.6    0.     1.     1. ]\n",
    " [  22.    64.  1006.1    1.     1.     1. ]\n",
    " [  21.8   64.  1006.2    2.     1.     1. ]\n",
    " [  21.6   64.  1005.5    3.     1.     1. ]\n",
    " [  21.3   65.  1004.8    4.     1.     1. ]\n",
    " [  20.9   66.  1003.9    5.     1.     1. ]\n",
    " [  21.2   64.  1003.2    6.     1.     1. ]\n",
    " [  21.1   64.  1002.4    7.     1.     1. ]\n",
    " [  20.7   65.  1002.2    8.     1.     1. ]\n",
    " [  19.5   73.  1002.9    9.     1.     1. ]\n",
    " [  19.6   72.  1003.9   10.     1.     1. ]\n",
    " [  20.2   69.  1004.6   11.     1.     1. ]\n",
    " [  21.6   64.  1005.    12.     1.     1. ]\n",
    " [  22.1   63.  1004.9   13.     1.     1. ]\n",
    " [  22.5   65.  1004.6   14.     1.     1. ]\n",
    " [  22.9   63.  1004.3   15.     1.     1. ]\n",
    " [  23.3   62.  1003.6   16.     1.     1. ]\n",
    " [  23.2   63.  1003.3   17.     1.     1. ]\n",
    " [  24.    61.  1002.9   18.     1.     1. ]\n",
    " [  23.8   58.  1003.4   19.     1.     1. ]\n",
    " [  23.6   59.  1003.    20.     1.     1. ]\n",
    " [  23.1   63.  1002.8   21.     1.     1. ]\n",
    " [  22.5   67.  1002.9   22.     1.     1. ]\n",
    " [  22.5   67.  1003.8   23.     1.     1. ]]\n",
    "Predict this y: \n",
    " [  22.2   67.  1004.4    0.     2.     1. ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87972626,  0.16462007, -1.4166927 , -1.66145972, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 1.00995708, -0.38206422, -1.20653737, -1.51699757, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 0.94484167, -0.38206422, -1.16450631, -1.37253542, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 0.87972626, -0.38206422, -1.45872377, -1.22807327, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 0.78205315, -0.24539315, -1.75294123, -1.08361112, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 0.65182233, -0.10872208, -2.13122082, -0.93914898, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 0.74949544, -0.38206422, -2.42543829, -0.79468683, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 0.71693774, -0.38206422, -2.76168681, -0.65022468, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 0.58670692, -0.24539315, -2.84574895, -0.50576253, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 0.19601448,  0.84797544, -2.55153148, -0.36130038, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 0.22857218,  0.71130437, -2.13122082, -0.21683823, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 0.4239184 ,  0.30129115, -1.83700336, -0.07237608, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 0.87972626, -0.38206422, -1.6688791 ,  0.07208606, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 1.04251478, -0.5187353 , -1.71091016,  0.21654821, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 1.1727456 , -0.24539315, -1.83700336,  0.36101036, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 1.30297641, -0.5187353 , -1.96309656,  0.50547251, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 1.43320723, -0.65540637, -2.25731402,  0.64993466, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 1.40064953, -0.5187353 , -2.38340722,  0.79439681, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 1.66111116, -0.79207745, -2.55153148,  0.93885896, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 1.59599575, -1.20209067, -2.34137615,  1.0833211 , -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 1.53088034, -1.06541959, -2.50950042,  1.22778325, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 1.36809182, -0.5187353 , -2.59356255,  1.3722454 , -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 1.1727456 ,  0.027949  , -2.55153148,  1.51670755, -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 1.1727456 ,  0.027949  , -2.17325189,  1.6611697 , -1.67374551,\n",
       "        -1.51053581],\n",
       "       [ 1.07507249,  0.027949  , -1.92106549, -1.66145972, -1.56006327,\n",
       "        -1.51053581],\n",
       "       [ 1.00995708,  0.027949  , -1.6688791 , -1.51699757, -1.56006327,\n",
       "        -1.51053581]])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-359-cf5c3562ce13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m array([[  21.6,   68. , 1005.6,    0. ,    1. ,    1. ],\n\u001b[0m\u001b[1;32m      2\u001b[0m        \u001b[0;34m[\u001b[0m  \u001b[0;36m22.\u001b[0m \u001b[0;34m,\u001b[0m   \u001b[0;36m64.\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1006.1\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;36m1.\u001b[0m \u001b[0;34m,\u001b[0m    \u001b[0;36m1.\u001b[0m \u001b[0;34m,\u001b[0m    \u001b[0;36m1.\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m        \u001b[0;34m[\u001b[0m  \u001b[0;36m21.8\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;36m64.\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1006.2\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;36m2.\u001b[0m \u001b[0;34m,\u001b[0m    \u001b[0;36m1.\u001b[0m \u001b[0;34m,\u001b[0m    \u001b[0;36m1.\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0;34m[\u001b[0m  \u001b[0;36m21.6\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;36m64.\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1005.5\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;36m3.\u001b[0m \u001b[0;34m,\u001b[0m    \u001b[0;36m1.\u001b[0m \u001b[0;34m,\u001b[0m    \u001b[0;36m1.\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0;34m[\u001b[0m  \u001b[0;36m21.3\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;36m65.\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1004.8\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;36m4.\u001b[0m \u001b[0;34m,\u001b[0m    \u001b[0;36m1.\u001b[0m \u001b[0;34m,\u001b[0m    \u001b[0;36m1.\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'array' is not defined"
     ]
    }
   ],
   "source": [
    "array([[  21.6,   68. , 1005.6,    0. ,    1. ,    1. ],\n",
    "       [  22. ,   64. , 1006.1,    1. ,    1. ,    1. ],\n",
    "       [  21.8,   64. , 1006.2,    2. ,    1. ,    1. ],\n",
    "       [  21.6,   64. , 1005.5,    3. ,    1. ,    1. ],\n",
    "       [  21.3,   65. , 1004.8,    4. ,    1. ,    1. ],\n",
    "       [  20.9,   66. , 1003.9,    5. ,    1. ,    1. ],\n",
    "       [  21.2,   64. , 1003.2,    6. ,    1. ,    1. ],\n",
    "       [  21.1,   64. , 1002.4,    7. ,    1. ,    1. ],\n",
    "       [  20.7,   65. , 1002.2,    8. ,    1. ,    1. ],\n",
    "       [  19.5,   73. , 1002.9,    9. ,    1. ,    1. ],\n",
    "       [  19.6,   72. , 1003.9,   10. ,    1. ,    1. ],\n",
    "       [  20.2,   69. , 1004.6,   11. ,    1. ,    1. ],\n",
    "       [  21.6,   64. , 1005. ,   12. ,    1. ,    1. ],\n",
    "       [  22.1,   63. , 1004.9,   13. ,    1. ,    1. ],\n",
    "       [  22.5,   65. , 1004.6,   14. ,    1. ,    1. ],\n",
    "       [  22.9,   63. , 1004.3,   15. ,    1. ,    1. ],\n",
    "       [  23.3,   62. , 1003.6,   16. ,    1. ,    1. ],\n",
    "       [  23.2,   63. , 1003.3,   17. ,    1. ,    1. ],\n",
    "       [  24. ,   61. , 1002.9,   18. ,    1. ,    1. ],\n",
    "       [  23.8,   58. , 1003.4,   19. ,    1. ,    1. ],\n",
    "       [  23.6,   59. , 1003. ,   20. ,    1. ,    1. ],\n",
    "       [  23.1,   63. , 1002.8,   21. ,    1. ,    1. ],\n",
    "       [  22.5,   67. , 1002.9,   22. ,    1. ,    1. ],\n",
    "       [  22.5,   67. , 1003.8,   23. ,    1. ,    1. ],\n",
    "       [  22.2,   67. , 1004.4,    0. ,    2. ,    1. ],\n",
    "       [  22. ,   67. , 1005. ,    1. ,    2. ,    1. ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnHM = tf.keras.Sequential()\n",
    "#nnHM.add(tf.keras.layers.Dense(24,input_shape=(2,),activation='relu')) # this is the input shape if you pass 2 variables\n",
    "# Adding more `lstm_units` just overfits more quickly.\n",
    "nnHM.add(tf.keras.layers.Dense(168,activation='relu',input_shape=(winSize,numFeatures,)))\n",
    "#nnHM.add(tf.keras.layers.LSTM(144,activation='relu',input_shape=(winSize,numFeatures,),return_sequences=True))\n",
    "nnHM.add(tf.keras.layers.LSTM(24,return_sequences=True))\n",
    "nnHM.add(tf.keras.layers.SimpleRNN(6,return_sequences=False))\n",
    "nnHM.add(tf.keras.layers.Flatten())\n",
    "nnHM.add(tf.keras.layers.Dense(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "221/221 [==============================] - 40s 151ms/step - loss: 0.4372 - mean_squared_error: 0.3353 - val_loss: 0.3554 - val_mean_squared_error: 0.2259\n",
      "Epoch 2/2\n",
      "221/221 [==============================] - 34s 155ms/step - loss: 0.2906 - mean_squared_error: 0.1564 - val_loss: 0.2935 - val_mean_squared_error: 0.1739\n"
     ]
    }
   ],
   "source": [
    "nnHM.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss='mae', # 'mean_absolute_error',\n",
    "    metrics=[tf.keras.metrics.MeanSquaredError()]\n",
    ")\n",
    "history = nnHM.fit_generator(\n",
    "    train_gen,\n",
    "    epochs=2,\n",
    "    verbose=1,\n",
    "    shuffle=False,\n",
    "    validation_data=test_gen\n",
    ")\n",
    "\n",
    "# 221/221 [==============================] - 30s 136ms/step - loss: 0.1939 - mean_squared_error: 0.0804 - val_loss: 0.2382 - val_mean_squared_error: 0.1322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 720ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.17476374, -0.7801555 , -0.00289125]], dtype=float32)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastTrainBatch = train_df[-24:]\n",
    "lastTrainBatch = np.array(lastTrainBatch)\n",
    "# now reshape this lastTrainBatch to meet what input_shape the model expects\n",
    "lastTrainBatch = lastTrainBatch.reshape((1,winSize,numFeatures))\n",
    "lstmPred = nnHM.predict(lastTrainBatch,verbose=1)\n",
    "lstmPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3114, 3)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nnHM.predict_generator(test_gen,verbose=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# de-normalize\n",
    "X = pandas.DataFrame(x)\n",
    "#X.columns = ['Ts_Valor','HR_Valor','QFE_Valor','hour','day','month']\n",
    "X.columns = ['Ts_Valor','HR_Valor','QFE_Valor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ts_Valor</th>\n",
       "      <th>HR_Valor</th>\n",
       "      <th>QFE_Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.290259</td>\n",
       "      <td>62.997636</td>\n",
       "      <td>1009.024455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.185517</td>\n",
       "      <td>62.959661</td>\n",
       "      <td>1008.849968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.615544</td>\n",
       "      <td>63.983202</td>\n",
       "      <td>1008.550531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.415523</td>\n",
       "      <td>62.110045</td>\n",
       "      <td>1007.588852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.250548</td>\n",
       "      <td>60.880337</td>\n",
       "      <td>1007.921384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>16.945654</td>\n",
       "      <td>70.603444</td>\n",
       "      <td>1010.435167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>16.475122</td>\n",
       "      <td>72.561553</td>\n",
       "      <td>1010.386923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>15.808300</td>\n",
       "      <td>75.956146</td>\n",
       "      <td>1010.611781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>15.915052</td>\n",
       "      <td>75.436123</td>\n",
       "      <td>1010.872343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>15.694439</td>\n",
       "      <td>75.174371</td>\n",
       "      <td>1011.307463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3114 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ts_Valor   HR_Valor    QFE_Valor\n",
       "0     18.290259  62.997636  1009.024455\n",
       "1     18.185517  62.959661  1008.849968\n",
       "2     17.615544  63.983202  1008.550531\n",
       "3     18.415523  62.110045  1007.588852\n",
       "4     18.250548  60.880337  1007.921384\n",
       "...         ...        ...          ...\n",
       "3109  16.945654  70.603444  1010.435167\n",
       "3110  16.475122  72.561553  1010.386923\n",
       "3111  15.808300  75.956146  1010.611781\n",
       "3112  15.915052  75.436123  1010.872343\n",
       "3113  15.694439  75.174371  1011.307463\n",
       "\n",
       "[3114 rows x 3 columns]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varToPred = ['Ts_Valor','HR_Valor','QFE_Valor']\n",
    "X = X*train_std[varToPred]+train_mean[varToPred]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[lendf:len(df)]\n",
    "test_labels = df[lendf:len(df)]\n",
    "#test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_labels = test_labels*train_std[varToPred]+train_mean[varToPred]\n",
    "test_labels = test_labels*train_std+train_mean\n",
    "test_labels = test_labels.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "### the offseted prediction works wonders -offset by 24 hours-\n",
    "plt.plot(test_labels[['Ts_Valor']],label='testDF')\n",
    "plt.plot(X[['Ts_Valor']],label='dense+lstm')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HR_Valor    -0.543562\n",
       "QFE_Valor    0.050571\n",
       "Ts_Valor    -0.278398\n",
       "day               NaN\n",
       "hour              NaN\n",
       "month             NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (X - test_labels).mean()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ídem a iteraciones anteriores, estos valores de error promedio no son suficientes para asegurar la calidad del modelo, se debe evaluar su capacidad de retroalimentación en tiempo real, por lo tanto se genera un nuevo proceso de retroalimentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "now = pandas.to_datetime('2021-07-29 09:00:00')\n",
    "now = pandas.to_datetime('2021-03-23 06:00:00')\n",
    "df3 = train_df[-24:]\n",
    "stackPreds = pandas.DataFrame()\n",
    "lastTrainBatch = train_df[-24:]\n",
    "# now reshape this lastTrainBatch to meet what input_shape the model expects\n",
    "lastTrainBatch = lastTrainBatch.reshape((1,winSize,numFeatures))\n",
    "x = nnHM.predict(lastTrainBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def norm(value,index):\n",
    "    #value = (value - modelMean[index]) / modelStd[index]\n",
    "    value = (value - train_mean[index]) / train_std[index]\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0,72):\n",
    "    delta = now + datetime.timedelta(0,i*3600)\n",
    "    #temp = np.array([x,y,z,delta.hour,delta.day,delta.month],dtype=\"float32\")\n",
    "    # temp = np.array([x,y,z,norm(delta.hour,3),norm(delta.day,4),norm(delta.month,5)],dtype=\"float32\")\n",
    "    temp = np.array([x[0,0],x[0,1],x[0,2],norm(delta.hour,3),norm(delta.day,4),norm(delta.month,5)],dtype=\"float32\")\n",
    "    stackPreds = stackPreds.append(pandas.DataFrame(temp).transpose())\n",
    "    # df3 = np.vstack((df3[0],temp))\n",
    "    # df4 = np.vstack((df4,temp))\n",
    "    cde = np.reshape(df3,(24,6))\n",
    "    df3 = np.vstack((cde,temp))\n",
    "    df3 = np.delete(df3, (0), axis=0)\n",
    "    df3 = np.reshape(df3,(-1,24,6))\n",
    "    x = nnHM.predict(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ts_Valor</th>\n",
       "      <th>HR_Valor</th>\n",
       "      <th>QFE_Valor</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.361166</td>\n",
       "      <td>61.087231</td>\n",
       "      <td>1008.963706</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.087312</td>\n",
       "      <td>60.659646</td>\n",
       "      <td>1009.144957</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.859438</td>\n",
       "      <td>60.006028</td>\n",
       "      <td>1009.346071</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.760234</td>\n",
       "      <td>59.101864</td>\n",
       "      <td>1009.324442</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.745547</td>\n",
       "      <td>58.306564</td>\n",
       "      <td>1009.413465</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>15.645422</td>\n",
       "      <td>71.734354</td>\n",
       "      <td>1010.906494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>15.421414</td>\n",
       "      <td>72.860856</td>\n",
       "      <td>1011.048804</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>15.152991</td>\n",
       "      <td>74.258594</td>\n",
       "      <td>1010.824200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>14.902286</td>\n",
       "      <td>75.537915</td>\n",
       "      <td>1010.458525</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>14.755248</td>\n",
       "      <td>76.387996</td>\n",
       "      <td>1010.112148</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ts_Valor   HR_Valor    QFE_Valor  hour   day  month\n",
       "0   18.361166  61.087231  1008.963706   6.0  23.0    3.0\n",
       "1   18.087312  60.659646  1009.144957   7.0  23.0    3.0\n",
       "2   17.859438  60.006028  1009.346071   8.0  23.0    3.0\n",
       "3   17.760234  59.101864  1009.324442   9.0  23.0    3.0\n",
       "4   17.745547  58.306564  1009.413465  10.0  23.0    3.0\n",
       "..        ...        ...          ...   ...   ...    ...\n",
       "67  15.645422  71.734354  1010.906494   1.0  26.0    3.0\n",
       "68  15.421414  72.860856  1011.048804   2.0  26.0    3.0\n",
       "69  15.152991  74.258594  1010.824200   3.0  26.0    3.0\n",
       "70  14.902286  75.537915  1010.458525   4.0  26.0    3.0\n",
       "71  14.755248  76.387996  1010.112148   5.0  26.0    3.0\n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackPreds = stackPreds.reset_index(drop=True)\n",
    "stackPreds.columns = ['Ts_Valor','HR_Valor','QFE_Valor','hour','day','month']\n",
    "stackPreds = stackPreds*train_std+train_mean\n",
    "stackPreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 62ms/step\n"
     ]
    }
   ],
   "source": [
    "predTest = nnHM.predict(test_gen,verbose=1)\n",
    "predTest = predTest*train_std[varToPred].to_numpy()+train_mean[varToPred].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"./dataPreprocessed.csv\")\n",
    "df = createTimeFeatures(df)\n",
    "dates_df = df.pop('utc')\n",
    "dates_df = df.pop('minute')\n",
    "dates_df = df.pop('year')\n",
    "test_df = df[lendf:len(df)]\n",
    "test_labels = df[['Ts_Valor','HR_Valor','QFE_Valor']][lendf:len(df)]\n",
    "test_labels = test_labels.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ts_Valor</th>\n",
       "      <th>HR_Valor</th>\n",
       "      <th>QFE_Valor</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28243</th>\n",
       "      <td>19.4</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1008.9</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28244</th>\n",
       "      <td>19.4</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1008.6</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28245</th>\n",
       "      <td>19.9</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28246</th>\n",
       "      <td>19.9</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28247</th>\n",
       "      <td>18.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31376</th>\n",
       "      <td>16.9</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1009.9</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31377</th>\n",
       "      <td>16.1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1010.1</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31378</th>\n",
       "      <td>15.9</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1010.5</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31379</th>\n",
       "      <td>15.6</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1011.2</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31380</th>\n",
       "      <td>15.6</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1011.7</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3138 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ts_Valor  HR_Valor  QFE_Valor  hour  day  month\n",
       "28243      19.4      63.0     1008.9     6   23      3\n",
       "28244      19.4      62.0     1008.6     7   23      3\n",
       "28245      19.9      62.0     1008.0     8   23      3\n",
       "28246      19.9      59.0     1007.9     9   23      3\n",
       "28247      18.5      65.0     1008.0    10   23      3\n",
       "...         ...       ...        ...   ...  ...    ...\n",
       "31376      16.9      72.0     1009.9    19   31      7\n",
       "31377      16.1      76.0     1010.1    20   31      7\n",
       "31378      15.9      76.0     1010.5    21   31      7\n",
       "31379      15.6      77.0     1011.2    22   31      7\n",
       "31380      15.6      78.0     1011.7    23   31      7\n",
       "\n",
       "[3138 rows x 6 columns]"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_labels['Ts_Valor'], label='testLabels')\n",
    "plt.plot(predTest[0:,0],label='predTestDF')\n",
    "plt.plot(stackPreds['Ts_Valor'],label='predAutonoma')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_labels['HR_Valor'], label='testLabels')\n",
    "plt.plot(predTest[0:,1],label='predTestDF')\n",
    "plt.plot(stackPreds['HR_Valor'],label='predAutonoma')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HR_Valor     7.588925\n",
       "QFE_Valor    1.922293\n",
       "Ts_Valor    -4.633723\n",
       "day               NaN\n",
       "hour              NaN\n",
       "month             NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = stackPreds - test_labels[:72]\n",
    "a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nnHM.save(\"../../backup/lstmMIMO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnHM = tf.keras.models.load_model(\"../../backup/lstmMIMO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python39664bitb48f37e888a140808da316066f1ee86a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
